{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41947c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import subprocess\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81491a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to client libraries\n",
    "\n",
    "openai = OpenAI()\n",
    "ollama_url = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(api_key=\"ollama\", base_url=ollama_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3eecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-oss:20b\", \"llama3.2:latest\", \"llama3.1:8b\", \"gemma3:270m\",]\n",
    "clients ={\"gpt-oss:20b\":ollama, \"llama3.2:latest\":ollama, \"llama3.1:8b\":ollama, \"gemma3:270m\":ollama}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "376da8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'os': {'system': 'Windows',\n",
       "  'arch': 'AMD64',\n",
       "  'release': '11',\n",
       "  'version': '10.0.26200',\n",
       "  'kernel': '11',\n",
       "  'distro': None,\n",
       "  'wsl': False,\n",
       "  'rosetta2_translated': False,\n",
       "  'target_triple': 'mingw32'},\n",
       " 'package_managers': ['winget'],\n",
       " 'cpu': {'brand': 'AMD Ryzen 7 5800HS with Radeon Graphics',\n",
       "  'cores_logical': 16,\n",
       "  'cores_physical': 8,\n",
       "  'simd': []},\n",
       " 'toolchain': {'compilers': {'gcc': 'gcc.exe (MinGW.org GCC-6.3.0-1) 6.3.0',\n",
       "   'g++': 'g++.exe (MinGW.org GCC-6.3.0-1) 6.3.0',\n",
       "   'clang': '',\n",
       "   'msvc_cl': ''},\n",
       "  'build_tools': {'cmake': '', 'ninja': '', 'make': ''},\n",
       "  'linkers': {'ld_lld': ''}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from system_info import retrieve_system_info\n",
    "\n",
    "system_info = retrieve_system_info()\n",
    "system_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0124c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = f\"\"\"\n",
    "Here is a report of the system information for my computer.\n",
    "I want to run a C++ compiler to compile a single C++ file called main.cpp and then execute it in the simplest way possible.\n",
    "Please reply with whether I need to install any C++ compiler to do this. If so, please provide the simplest step by step instructions to do so.\n",
    "\n",
    "If I'm already set up to compile C++ code, then I'd like to run something like this in Python to compile and execute the code:\n",
    "```python\n",
    "compile_command = # something here - to achieve the fastest possible runtime performance\n",
    "compile_result = subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
    "run_command = # something here\n",
    "run_result = subprocess.run(run_command, check=True, text=True, capture_output=True)\n",
    "return run_result.stdout\n",
    "```\n",
    "Please tell me exactly what I should use for the compile_command and run_command.\n",
    "\n",
    "System information:\n",
    "{system_info}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6697b971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 1. Is a compiler already on your system?\n",
       "\n",
       "Your system information shows that **MinGW‑GCC 6.3.0** is already installed:\n",
       "\n",
       "```text\n",
       "'g++': 'g++.exe (MinGW.org GCC-6.3.0-1) 6.3.0'\n",
       "```\n",
       "\n",
       "You can confirm this from a PowerShell / CMD window:\n",
       "\n",
       "```powershell\n",
       "> g++ --version\n",
       "```\n",
       "\n",
       "If you get a version number (as above) you’re good to go – *you do **not** need to install another compiler*.\n",
       "\n",
       "> **But** GCC 6.3 is a bit old. If you care about the very best runtime performance (especially on a Ryzen 5800HS), you might want to upgrade to a newer toolchain (e.g. GCC 10+, Clang 14+, or MSVC).  \n",
       ">  Installing a newer compiler is optional – it’s only required if you want that extra speed.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Upgrade the compiler (optional)\n",
       "\n",
       "If you decide to upgrade via winget, the quick one‑liner is:\n",
       "\n",
       "```powershell\n",
       "winget install -e --id \"MinGW.Compilers\"\n",
       "```\n",
       "\n",
       "(This installs MinGW‑w64 GCC 11+ and places `g++` in your PATH.)\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Python harness to compile **and** run a single file\n",
       "\n",
       "Below is a *minimal*, *fastest‑in‑practice* sequence for compiling `main.cpp`\n",
       "with GCC and executing the resulting binary.\n",
       "\n",
       "```python\n",
       "import subprocess\n",
       "import pathlib\n",
       "\n",
       "# ------------------------------------------------------------------\n",
       "# Step 1: build the C++ file into a native Win32 .exe\n",
       "# ------------------------------------------------------------------\n",
       "compile_command = [\n",
       "    \"g++\",\n",
       "    \"main.cpp\",                 # input source file\n",
       "    \"-O3\",                      # aggressive optimisation\n",
       "    \"-std=c++17\",               # language standard (pick the one you need)\n",
       "    \"-march=native\",            # tune for your CPU\n",
       "    \"-flto\",                    # link‑time optimisation (if supported)\n",
       "    \"-s\",                       # strip debug symbols in the final binary\n",
       "    \"-o\", \"main.exe\"            # output binary\n",
       "]\n",
       "\n",
       "# Run the compiler\n",
       "compile_process = subprocess.run(\n",
       "    compile_command,          # list of command‑line parts\n",
       "    check=True,               # raise on non‑zero exit\n",
       "    capture_output=True,      # capture stdout & stderr\n",
       "    text=True                 # return string, not bytes\n",
       ")\n",
       "\n",
       "# compile_process.stdout   <-- usually empty for a successful build\n",
       "# compile_process.stderr   <-- compiler diagnostics if any\n",
       "\n",
       "# ------------------------------------------------------------------\n",
       "# Step 2: execute the freshly compiled binary\n",
       "# ------------------------------------------------------------------\n",
       "run_command = [\n",
       "    pathlib.Path.cwd() / \"main.exe\"   # absolute path – safer on Windows\n",
       "]\n",
       "\n",
       "run_process = subprocess.run(\n",
       "    run_command,\n",
       "    check=True,            # raise if the program exits non‑zero\n",
       "    capture_output=True,\n",
       "    text=True\n",
       ")\n",
       "\n",
       "# ------------------------------------------------------------------\n",
       "# Result\n",
       "# ------------------------------------------------------------------\n",
       "print(\"Program output:\\n\", run_process.stdout)\n",
       "```\n",
       "\n",
       "#### Why this particular `g++` command gives the best speed?\n",
       "\n",
       "| Flag | Purpose |\n",
       "|------|---------|\n",
       "| `-O3` | Full optimisation set – fastest (but potentially larger) |\n",
       "| `-march=native` | Generates code tuned to your exact CPU (Ryzen 5800HS – AVX‑512‑like instructions) |\n",
       "| `-flto` | Performs inter‑module optimisation across the whole binary (GCC 6+ supports it) |\n",
       "| `-s` | Strips symbols, shrinking the binary, which can help with startup time |\n",
       "| `-o main.exe` | Guarantees the binary name; eliminates the default `a.exe` confusion |\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Quick note on alternative toolchains\n",
       "\n",
       "If you prefer **MSVC** (likely the fastest on Windows for x86‑64) or **Clang/LLVM**, the same idea applies:\n",
       "\n",
       "| Tool | Compile command (simplified) | Run command |\n",
       "|------|----------------------------|------------|\n",
       "| MSVC (`cl.exe`) | `[\"cl\", \"/EHsc\", \"/O2\", \"/std:c++17\", \"/Fe:main.exe\", \"main.cpp\"]` | `[\"main.exe\"]` |\n",
       "| Clang (`clang++`) | `[\"clang++\", \"-O3\", \"-std=c++17\", \"-march=native\", \"-o\", \"main.exe\", \"main.cpp\"]` | `[\"main.exe\"]` |\n",
       "\n",
       "Just replace `g++` with the corresponding executable and rerun the Python harness.\n",
       "\n",
       "---\n",
       "\n",
       "### 5. Summary\n",
       "\n",
       "| ✅ | Result |\n",
       "|---|--------|\n",
       "| **Compiler installed?** | Yes – MinGW‑GCC 6.3 is already present. |\n",
       "| **Upgrade needed?** | Not mandatory, but newer GCC/Clang/MSVC will give you the *fastest* possible binaries. |\n",
       "| **Python compile‑run code** | Provided above – adjust only the compiler if you upgrade. |\n",
       "| **Execution** | `subprocess.run([\"...\",\"main.exe\"], …)` – the binary launches immediately. |\n",
       "\n",
       "Enjoy compiling with the speed‑oriented command set above!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = ollama.chat.completions.create(model=models[0], messages=[{\"role\": \"user\", \"content\": message}])\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c944aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_command = [\n",
    "                \"g++\",\n",
    "                \"main.cpp\",\n",
    "                \"-o\",\n",
    "                \"main.exe\"\n",
    "]\n",
    "\n",
    "run_command = [\"./main\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75610c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"C++\" \n",
    "extension = \"cpp\"\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "Your task is to convert Python code into high performance {language} code.\n",
    "Respond only with {language} code. Do not provide any explanation other than occasional comments.\n",
    "The {language} response needs to produce an identical output in the fastest possible time.\n",
    "\"\"\"\n",
    "\n",
    "def user_prompt_for(python):\n",
    "    return f\"\"\"\n",
    "Port this Python code to {language} with the fastest possible implementation that produces identical output in the least time.\n",
    "The system information is:\n",
    "{system_info}\n",
    "Your response will be written to a file called main.{language} and then compiled and executed; the compilation command is:\n",
    "{compile_command}\n",
    "Respond only with {language} code.\n",
    "Python code to port:\n",
    "\n",
    "```python\n",
    "{python}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1558ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(python):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
    "    ]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "decf0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(code):\n",
    "    with open(f\"main.{extension}\", \"w\") as f:\n",
    "        f.write(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40d2e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def port(model, python):\n",
    "    client = clients[model]\n",
    "    response = client.chat.completions.create(model=model, messages=messages_for(python))\n",
    "    reply = response.choices[0].message.content\n",
    "    reply = reply.replace('```cpp','').replace('```','')\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "244f8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_python(code):\n",
    "    globals_dict = {\"__builtins__\": __builtins__}\n",
    "\n",
    "    buffer = io.StringIO()\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = buffer\n",
    "\n",
    "    try:\n",
    "        exec(code, globals_dict)\n",
    "        output = buffer.getvalue()\n",
    "    except Exception as e:\n",
    "        output = f\"Error: {e}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c4bc8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_run(code):\n",
    "    write_output(code)\n",
    "    try:\n",
    "        subprocess.run(compile_command, check=True, text=True, capture_output=True)\n",
    "        run_result = subprocess.run(run_command, check=True, text=True, capture_output=True)\n",
    "        return run_result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"An error occurred:\\n{e.stderr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f4d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_hard = \"\"\"# Be careful to support large numbers\n",
    "\n",
    "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
    "    value = seed\n",
    "    while True:\n",
    "        value = (a * value + c) % m\n",
    "        yield value\n",
    "        \n",
    "def max_subarray_sum(n, seed, min_val, max_val):\n",
    "    lcg_gen = lcg(seed)\n",
    "    random_numbers = [next(lcg_gen) % (max_val - min_val + 1) + min_val for _ in range(n)]\n",
    "    max_sum = float('-inf')\n",
    "    for i in range(n):\n",
    "        current_sum = 0\n",
    "        for j in range(i, n):\n",
    "            current_sum += random_numbers[j]\n",
    "            if current_sum > max_sum:\n",
    "                max_sum = current_sum\n",
    "    return max_sum\n",
    "\n",
    "def total_max_subarray_sum(n, initial_seed, min_val, max_val):\n",
    "    total_sum = 0\n",
    "    lcg_gen = lcg(initial_seed)\n",
    "    for _ in range(20):\n",
    "        seed = next(lcg_gen)\n",
    "        total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
    "    return total_sum\n",
    "\n",
    "# Parameters\n",
    "n = 10000         # Number of random numbers\n",
    "initial_seed = 42 # Initial seed for the LCG\n",
    "min_val = -10     # Minimum value of random numbers\n",
    "max_val = 10      # Maximum value of random numbers\n",
    "\n",
    "# Timing the function\n",
    "import time\n",
    "start_time = time.time()\n",
    "result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Total Maximum Subarray Sum (20 runs):\", result)\n",
    "print(\"Execution Time: {:.6f} seconds\".format(end_time - start_time))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd61a902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rujjul Saha\\AppData\\Local\\Temp\\ipykernel_3400\\79197944.py:3: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: theme, css. Please pass these parameters to launch() instead.\n",
      "  with gr.Blocks(css=CSS, theme=gr.themes.Monochrome(), title=f\"Port from Python to {language}\") as ui:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from styles import CSS\n",
    "\n",
    "with gr.Blocks(css=CSS, theme=gr.themes.Monochrome(), title=f\"Port from Python to {language}\") as ui:\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=6):\n",
    "            python = gr.Code(\n",
    "                label=\"Python (original)\",\n",
    "                value=python_hard,\n",
    "                language=\"python\",\n",
    "                lines=26\n",
    "            )\n",
    "        with gr.Column(scale=6):\n",
    "            cpp = gr.Code(\n",
    "                label=f\"{language} (generated)\",\n",
    "                value=\"\",\n",
    "                language=\"cpp\",\n",
    "                lines=26\n",
    "            )\n",
    "\n",
    "    with gr.Row(elem_classes=[\"controls\"]):\n",
    "        python_run = gr.Button(\"Run Python\", elem_classes=[\"run-btn\", \"py\"])\n",
    "        model = gr.Dropdown(models, value=models[0], show_label=False)\n",
    "        convert = gr.Button(f\"Port to {language}\", elem_classes=[\"convert-btn\"])\n",
    "        cpp_run = gr.Button(f\"Run {language}\", elem_classes=[\"run-btn\", \"cpp\"])\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=6):\n",
    "            python_out = gr.TextArea(label=\"Python result\", lines=8, elem_classes=[\"py-out\"])\n",
    "        with gr.Column(scale=6):\n",
    "            cpp_out = gr.TextArea(label=f\"{language} result\", lines=8, elem_classes=[\"cpp-out\"])\n",
    "\n",
    "    convert.click(fn=port, inputs=[model, python], outputs=[cpp])\n",
    "    python_run.click(fn=run_python, inputs=[python], outputs=[python_out])\n",
    "    cpp_run.click(fn=compile_and_run, inputs=[cpp], outputs=[cpp_out])\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
